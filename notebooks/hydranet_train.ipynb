{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train HydraNet for WikiSQL benchmark\n",
    "\n",
    "## Prerequisites:\n",
    "- Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning (AML)\n",
    "- Install the Python SDK:  make sure to install notebook, and contrib\n",
    "    ```\n",
    "    conda create -n azureml -y Python=3.6\n",
    "    source activate azureml\n",
    "    pip install --upgrade azureml-sdk[notebooks,contrib]\n",
    "    conda install ipywidgets\n",
    "    jupyter nbextension install --py --user azureml.widgets\n",
    "    jupyter nbextension enable azureml.widgets --user --py\n",
    "    ```\n",
    " \n",
    "You will need to restart jupyter after this\n",
    "Detailed instructions are here: https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import AzureML SDK and initialize workspace\n",
    "\n",
    "To create or access an Azure ML Workspace, you will need to import the AML library and the following information:\n",
    "- A name for your workspace\n",
    "- Your subscription id\n",
    "- The resource group name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget\n",
    "# Import AzureML Libraries\n",
    "import azureml.core\n",
    "from azureml.core import Datastore, Dataset,Experiment, Workspace, RunConfiguration, ContainerRegistry, Environment\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azureml.core.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.json', 'r') as config_file:\n",
    "    credentials = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve your workspace\n",
    "ws = Workspace.get(name=\"xiaoyzhu-turingrg\",\n",
    "                 subscription_id='a6c2a7cc-d67e-4a1a-b765-983f08c0423a',\n",
    "                  resource_group='xiaoyzhu-turingrg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Stores\n",
    "AML Workspace comes with a default data store. The training, validation and testing data is hosted <add description>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "# Create the compute cluster\n",
    "gpu_cluster_name = \"nd40-ssh-2\" \n",
    "\n",
    "# Verify that the cluster doesn't exist already\n",
    "try:\n",
    "    gpu_compute_target = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_ND40rs_v2', min_nodes=0, max_nodes=1)\n",
    "    \n",
    "    # create the cluster\n",
    "    gpu_compute_target = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "    gpu_compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore name: workspaceblobstore\n",
      "Container name: azureml-blobstore-1df38ad3-d561-413a-b8c5-603f11808774\n",
      "Datastore type: AzureBlob\n",
      "Workspace name: xiaoyzhu-turingrg\n"
     ]
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Print the workspace attributes\n",
    "print('Datastore name: ' + default_ds.name, \n",
    "      'Container name: ' + default_ds.container_name, \n",
    "      'Datastore type: ' + default_ds.datastore_type, \n",
    "      'Workspace name: ' + default_ds.workspace.name, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom environment based on Docker image \n",
    "\n",
    "We use a docker image built from the [Dockerfile](../dockerfile). Azure ML allows user to use a python environment in a custom docker image to run python scripts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment(name=\"myenv\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.docker.base_image = \"hydranet:v1\"\n",
    "myenv.docker.base_image_registry.address = \"marinchwus2a448b3c27.azurecr.io\"\n",
    "myenv.docker.base_image_registry.username = \"marinchwus2a448b3c27\"\n",
    "myenv.docker.base_image_registry.password = credentials[\"registry_password\"]\n",
    "myenv.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run fine-tuning PyTorch script\n",
    "Let us create a new PyTorch estimator to run the fine-tuning script `run_classifier.py`. \n",
    " \n",
    "AzureML provides mpi backend to launch python scripts in a process group. The helper module `azureml_adapter.py` sets up environment variables for pytorch so user can use `torch.distributed.init_process_group(backend=\"nccl\")` to initialize pytorch distributed process group with NCCL backend. \n",
    " \n",
    " \n",
    "PyTorch estimator parameters:\n",
    "- source_directory: the dictory of all source code to be executed in the remote compute target\n",
    "- compute_target: the compute target (created in the preparation step)\n",
    "- entry_script: the stript to be launched\n",
    "- node_count: how many nodes for the cluster to be created within the compute target to run this job\n",
    "- distributed_training: we use mpi to launch multiproces jobs in each node, allows pytorch to initialize process group using NCCL backend. Note that mpi configuration also sets number of processes for each node. This should be the same as the number of GPUs on each node. \n",
    "- environment_definition: use the custom environment. If omitted, Azure ML provides standard docker images for different pytorch versions.\n",
    " \n",
    "We explain a few script arguments, the rest are self-explainable\n",
    "- model_name_or_path: The location of the pretrained TuringV3 model\n",
    "- task_name: The GLUE task name. We use sst-2 here.\n",
    "- data_dir: The input of the training data from GLUE \n",
    "- output_dir: The output path of the fine-tuned model\n",
    "- per_gpu_train_batch_size: The batch size for each gpu in forward and backward steps\n",
    "- num_training_epochs: number of epochs to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If environment_definition or conda_dependencies_file_path is specified, Azure ML will not install any framework related packages on behalf of the user.\n"
     ]
    }
   ],
   "source": [
    "# workdir = \"/turing/workdir\"\n",
    "\n",
    "# mpi = MpiConfiguration()\n",
    "# mpi.process_count_per_node = 8 \n",
    "\n",
    "source_directory = '..'\n",
    "# model_checkpoint_path = \"NLRv3-Base-Uncased/tnlrv3-base.pt\"\n",
    "# dataset_path = 'glue/SST-2/'\n",
    "dataset_path = 'marinch/hydranet/'\n",
    "# output_path = 'outputs-marinch/hydranet-outputs/'\n",
    "\n",
    "train_est = PyTorch(source_directory=source_directory,\n",
    "                    compute_target=gpu_compute_target,\n",
    "                    script_params = {\n",
    "#                         '--model_name_or_path': ds.path(model_checkpoint_path).as_mount(),\n",
    "#                         '--task_name': 'sst-2',\n",
    "#                         '--tokenizer_name': './tnlrv3/tokenizer/tnlrv3-base-uncased-vocab.txt',\n",
    "#                         '--config_name': './tnlrv3/config/tnlrv3-base-uncased-config.json',\n",
    "#                         '--do_train': '',\n",
    "#                         '--do_lower_case':'', \n",
    "#                         '--evaluate_during_training':'',\n",
    "#                         '--data_dir':default_ds.path(dataset_path).as_mount(),\n",
    "#                         '--output_dir': default_ds.path(output_path).as_mount(),\n",
    "                        '--gpu': '0,1,2,3,4,5,6,7',\n",
    "#                         '--max_seq_length': 128, \n",
    "#                         '--per_gpu_train_batch_size': 32, \n",
    "#                         '--learning_rate': 7e-6,\n",
    "#                         '--num_train_epochs':2.0, # 25.0,\n",
    "#                         '--weight_decay':0.01, \n",
    "#                         '--warmup_ratio':0.2,\n",
    "#                         '--fp16':'',\n",
    "#                         '--fp16_opt_level': 'O2',\n",
    "#                         '--overwrite_output_dir':'',\n",
    "#                         '--do_eval':''\n",
    "                    },\n",
    "                    entry_script='notebooks/prep_and_train.py',\n",
    "#                     node_count=1,\n",
    "#                     distributed_training = mpi,\n",
    "                    environment_definition = myenv,\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training. On a Standard_ND40rs_v2 VM with 8 V100 GPUs, it takes about 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11503a3cec424f5c863767c1ee9778be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/HydraNet/runs/HydraNet_1597686510_e7f19474?wsid=/subscriptions/a6c2a7cc-d67e-4a1a-b765-983f08c0423a/resourcegroups/xiaoyzhu-turingrg/workspaces/xiaoyzhu-turingrg\", \"run_id\": \"HydraNet_1597686510_e7f19474\", \"run_properties\": {\"run_id\": \"HydraNet_1597686510_e7f19474\", \"created_utc\": \"2020-08-17T17:48:42.953543Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"26129401-c4ee-4404-a194-3cb493424f9b\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\", \"azureml.git.repository_uri\": \"https://github.com/inchiosa/HydraNet-WikiSQL\", \"mlflow.source.git.repoURL\": \"https://github.com/inchiosa/HydraNet-WikiSQL\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"ed4f8a649fedfe8d629e92cb2681e00614607956\", \"mlflow.source.git.commit\": \"ed4f8a649fedfe8d629e92cb2681e00614607956\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_e626dbf32bbb512cac60ea60e65ee2fe9066b9ece845e6016e20e278a8c379c3_d.txt\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/azureml-logs/55_azureml-execution-tvmps_e626dbf32bbb512cac60ea60e65ee2fe9066b9ece845e6016e20e278a8c379c3_d.txt?sv=2019-02-02&sr=b&sig=j7cMY3twk9tt1gYQ22PuiRUclvP39FX68R6PpH3UUrI%3D&st=2020-08-17T17%3A39%3A29Z&se=2020-08-18T01%3A49%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_e626dbf32bbb512cac60ea60e65ee2fe9066b9ece845e6016e20e278a8c379c3_d.txt\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/azureml-logs/65_job_prep-tvmps_e626dbf32bbb512cac60ea60e65ee2fe9066b9ece845e6016e20e278a8c379c3_d.txt?sv=2019-02-02&sr=b&sig=aM3EbaSq6gdyWLNO%2BckvlefC4fNdNw8oNMbKte0azg8%3D&st=2020-08-17T17%3A39%3A29Z&se=2020-08-18T01%3A49%3A29Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=FsRncvRQsPy3O%2BCIXjb7UIFbYQUyzyR8Vas0ORlQsfw%3D&st=2020-08-17T17%3A39%3A29Z&se=2020-08-18T01%3A49%3A29Z&sp=r\", \"azureml-logs/process_info.json\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=q6fU7F3DhMHa0UhJOAaY3AKxTL8S5afulhrVEZMJlc0%3D&st=2020-08-17T17%3A39%3A30Z&se=2020-08-18T01%3A49%3A30Z&sp=r\", \"azureml-logs/process_status.json\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=VAAdiaIZg3erVqhHHG0XyhMio6NkwPAIj%2BalRI%2BVhAM%3D&st=2020-08-17T17%3A39%3A30Z&se=2020-08-18T01%3A49%3A30Z&sp=r\", \"logs/azureml/156_azureml.log\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/logs/azureml/156_azureml.log?sv=2019-02-02&sr=b&sig=DZQntkP%2F8%2B5NOCuoKrEsKmJ45SkcYD2gJQ6xFbeW5eM%3D&st=2020-08-17T17%3A39%3A29Z&se=2020-08-18T01%3A49%3A29Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://xiaoyzhuturing3866514710.blob.core.windows.net/azureml/ExperimentRun/dcid.HydraNet_1597686510_e7f19474/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=cEKwAMwLs2DzLfGfEdR8oQ%2BXCAMw%2F2i8CZ2ITBIq7Bc%3D&st=2020-08-17T17%3A39%3A29Z&se=2020-08-18T01%3A49%3A29Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_e626dbf32bbb512cac60ea60e65ee2fe9066b9ece845e6016e20e278a8c379c3_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_e626dbf32bbb512cac60ea60e65ee2fe9066b9ece845e6016e20e278a8c379c3_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/156_azureml.log\"]], \"run_duration\": \"0:08:35\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2020-08-17T17:49:13.001541] Entering context manager injector.\\n[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['notebooks/prep_and_train.py', '--gpu', '0,1,2,3,4,5,6,7'])\\nStarting the daemon thread to refresh tokens in background for process with pid = 156\\nEntering Run History Context Manager.\\nCurrent directory:  /mnt/batch/tasks/shared/LS_root/jobs/xiaoyzhu-turingrg/azureml/hydranet_1597686510_e7f19474/mounts/workspaceblobstore/azureml/HydraNet_1597686510_e7f19474\\nPreparing to call script [ notebooks/prep_and_train.py ] with arguments: ['--gpu', '0,1,2,3,4,5,6,7']\\nAfter variable expansion, calling script [ notebooks/prep_and_train.py ] with arguments: ['--gpu', '0,1,2,3,4,5,6,7']\\n\\nScript type = None\\noutput:\\nb'total 84\\\\n-rwxrwxrwx 1 root root  1074 Aug 17 17:49 LICENSE\\\\n-rwxrwxrwx 1 root root  1010 Aug 17 17:49 README.md\\\\ndrwxrwxrwx 2 root root  4096 Aug 17 17:49 __pycache__\\\\ndrwxrwxrwx 2 root root  4096 Jan  1  1970 azureml-logs\\\\ndrwxrwxrwx 3 root root  4096 Aug 17 17:49 azureml-setup\\\\ndrwxrwxrwx 3 root root  4096 Aug 17 17:48 azureml_compute_logs\\\\ndrwxrwxrwx 2 root root  4096 Aug 17 17:49 conf\\\\n-rwxrwxrwx 1 root root  4705 Aug 17 17:49 evaluator.py\\\\n-rwxrwxrwx 1 root root     0 Aug 17 17:49 extract_project.success\\\\n-rwxrwxrwx 1 root root 11500 Aug 17 17:49 featurizer.py\\\\ndrwxrwxrwx 3 root root  4096 Aug 17 17:49 logs\\\\n-rwxrwxrwx 1 root root  3755 Aug 17 17:49 main.py\\\\ndrwxrwxrwx 2 root root  4096 Aug 17 17:49 modeling\\\\ndrwxrwxrwx 2 root root  4096 Aug 17 17:49 notebooks\\\\ndrwxrwxrwx 2 root root  4096 Jan  1  1970 outputs\\\\n-rwxrwxrwx 1 root root    46 Aug 17 17:49 requirements.txt\\\\n-rwxrwxrwx 1 root root  2516 Aug 17 17:49 utils.py\\\\n-rwxrwxrwx 1 root root  8149 Aug 17 17:49 wikisql_gendata.py\\\\ndrwxrwxrwx 2 root root  4096 Aug 17 17:49 wikisql_lib\\\\n-rwxrwxrwx 1 root root  3837 Aug 17 17:49 wikisql_prediction.py\\\\n'\\nerror:\\nNone\\nCloning into 'WikiSQL'...\\nChecking out files:  44% (16/36)   \\rChecking out files:  47% (17/36)   \\rChecking out files:  50% (18/36)   \\rChecking out files:  52% (19/36)   \\rChecking out files:  55% (20/36)   \\rChecking out files:  58% (21/36)   \\rChecking out files:  61% (22/36)   \\rChecking out files:  63% (23/36)   \\rChecking out files:  66% (24/36)   \\rChecking out files:  69% (25/36)   \\rChecking out files:  72% (26/36)   \\rChecking out files:  75% (27/36)   \\rChecking out files:  77% (28/36)   \\rChecking out files:  80% (29/36)   \\rChecking out files:  83% (30/36)   \\rChecking out files:  86% (31/36)   \\rChecking out files:  88% (32/36)   \\rChecking out files:  91% (33/36)   \\rChecking out files:  94% (34/36)   \\rChecking out files:  97% (35/36)   \\rChecking out files: 100% (36/36)   \\rChecking out files: 100% (36/36), done.\\noutput:\\nb''\\nerror:\\nNone\\noutput:\\nb'data/\\\\ndata/train.jsonl\\\\ndata/test.tables.jsonl\\\\ndata/test.db\\\\ndata/dev.tables.jsonl\\\\ndata/dev.db\\\\ndata/test.jsonl\\\\ndata/train.tables.jsonl\\\\ndata/train.db\\\\ndata/dev.jsonl\\\\n'\\nerror:\\nNone\\noutput:\\nb''\\nerror:\\nNone\\ntotal 4\\ndrwxrwxrwx 2 root root 4096 Aug 17 17:49 wikisql\\nexit_code:\\n0\\nargs.gpu:\\n0,1,2,3,4,5,6,7\\nprocessing data/wikisql/train.jsonl...\\n['necw heavyweight champion', ['necw', 'heavyweight', 'champion'], 'Who is the current champion in the NECW Heavyweight Championship?', ['Who', 'is', 'the', 'current', 'champion', 'in', 'the', 'NECW', 'Heavyweight', 'Championship', '?']]\\nprocessing data/wikisql/dev.jsonl...\\nprocessing data/wikisql/test.jsonl...\\n['Baccalaureate college', ['Baccalaureate', 'college'], 'What was the enrollment (2005) for baccalaureate colleges , for Granite State College?', ['What', 'was', 'the', 'enrollment', '(', '2005', ')', 'for', 'baccalaureate', 'colleges', ',', 'for', 'Granite', 'State', 'College', '?']]\\nexit_code:\\n0\\ncommand:\\npython main.py train --conf conf/wikisql.conf --gpu 0,1,2,3,4,5,6,7 --note \\\"ND40rs_v2\\\"\\n5000\\nvalue span is out of range\\nvalue span is out of range\\n10000\\nvalue span is out of range\\nvalue span is out of range\\n15000\\n20000\\n25000\\nvalue span is out of range\\n30000\\n35000\\n40000\\n45000\\n50000\\n55000\\n/mnt/batch/tasks/shared/LS_root/jobs/xiaoyzhu-turingrg/azureml/hydranet_1597686510_e7f19474/mounts/workspaceblobstore/azureml/HydraNet_1597686510_e7f19474/data/wikitrain.jsonl loaded. Data shapes:\\ninput_ids (360629, 96)\\ninput_mask (360629, 96)\\nsegment_ids (360629, 96)\\nagg (360629,)\\nselect (360629,)\\nwhere_num (360629,)\\nwhere (360629,)\\nop (360629,)\\nvalue_start (360629,)\\nvalue_end (360629,)\\ntotal_steps: 7043, warm_up_steps: 400\\n5000\\n/mnt/batch/tasks/shared/LS_root/jobs/xiaoyzhu-turingrg/azureml/hydranet_1597686510_e7f19474/mounts/workspaceblobstore/azureml/HydraNet_1597686510_e7f19474/data/wikidev.jsonl loaded. Data shapes:\\ninput_ids (53406, 96)\\ninput_mask (53406, 96)\\nsegment_ids (53406, 96)\\nagg (53406,)\\nselect (53406,)\\nwhere_num (53406,)\\nwhere (53406,)\\nop (53406,)\\nvalue_start (53406,)\\nvalue_end (53406,)\\nEval Data file /mnt/batch/tasks/shared/LS_root/jobs/xiaoyzhu-turingrg/azureml/hydranet_1597686510_e7f19474/mounts/workspaceblobstore/azureml/HydraNet_1597686510_e7f19474/data/wikidev.jsonl loaded, sample num = 53406\\n5000\\n10000\\n15000\\ndata/wikitest.jsonl loaded. Data shapes:\\ninput_ids (101066, 96)\\ninput_mask (101066, 96)\\nsegment_ids (101066, 96)\\nagg (101066,)\\nselect (101066,)\\nwhere_num (101066,)\\nwhere (101066,)\\nop (101066,)\\nvalue_start (101066,)\\nvalue_end (101066,)\\nEval Data file data/wikitest.jsonl loaded, sample num = 101066\\nstart training\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Bootstrap : Using [0]eth0:10.0.0.5<0>\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB ; OOB eth0:10.0.0.5<0>\\nNCCL version 2.4.8+cuda10.1\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO nranks 8\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Setting affinity for GPU 0 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO NCCL_TREE_THRESHOLD set by environment to 0.\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Setting affinity for GPU 1 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Setting affinity for GPU 2 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Setting affinity for GPU 3 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Setting affinity for GPU 4 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Setting affinity for GPU 5 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Setting affinity for GPU 6 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Setting affinity for GPU 7 to 0fffff\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Using 256 threads, Min Comp Cap 7, Trees disabled\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 00 :    0   1   2   4   3   5   6   7\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 01 :    0   2   1   7   6   3   4   5\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 02 :    0   2   7   1   3   6   4   5\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 03 :    0   5   4   3   6   7   1   2\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 04 :    0   5   4   6   3   1   7   2\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 05 :    0   7   6   5   3   4   2   1\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 06 :    0   1   2   4   3   5   6   7\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 07 :    0   2   1   7   6   3   4   5\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 08 :    0   2   7   1   3   6   4   5\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 09 :    0   5   4   3   6   7   1   2\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 10 :    0   5   4   6   3   1   7   2\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Channel 11 :    0   7   6   5   3   4   2   1\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 00 : 0[5] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 00 : 1[6] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 00 : 2[0] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 00 : 3[7] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 00 : 4[1] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 00 : 5[2] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 00 : 6[3] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 00 : 7[4] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 01 : 0[5] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 01 : 1[6] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 01 : 2[0] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 01 : 3[7] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 01 : 4[1] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 01 : 5[2] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 01 : 6[3] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 01 : 7[4] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 02 : 0[5] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 02 : 1[6] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 02 : 2[0] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 02 : 3[7] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 02 : 4[1] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 02 : 5[2] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 02 : 6[3] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 02 : 7[4] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 03 : 0[5] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 03 : 1[6] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 03 : 2[0] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 03 : 3[7] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 03 : 4[1] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 03 : 5[2] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 03 : 6[3] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 03 : 7[4] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 04 : 0[5] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 04 : 1[6] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 04 : 2[0] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 04 : 3[7] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 04 : 4[1] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 04 : 5[2] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 04 : 6[3] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 04 : 7[4] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 05 : 0[5] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 05 : 1[6] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 05 : 2[0] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 05 : 3[7] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 05 : 4[1] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 05 : 5[2] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 05 : 6[3] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 05 : 7[4] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 06 : 0[5] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 06 : 1[6] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 06 : 2[0] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 06 : 3[7] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 06 : 4[1] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 06 : 5[2] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 06 : 6[3] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 06 : 7[4] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 07 : 0[5] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 07 : 1[6] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 07 : 2[0] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 07 : 3[7] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 07 : 4[1] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 07 : 5[2] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 07 : 6[3] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 07 : 7[4] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 08 : 0[5] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 08 : 1[6] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 08 : 2[0] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 08 : 3[7] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 08 : 4[1] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 08 : 5[2] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 08 : 6[3] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 08 : 7[4] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 09 : 0[5] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 09 : 1[6] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 09 : 2[0] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 09 : 3[7] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 09 : 4[1] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 09 : 5[2] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 09 : 6[3] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 09 : 7[4] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 10 : 0[5] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 10 : 1[6] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 10 : 2[0] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 10 : 3[7] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 10 : 4[1] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 10 : 5[2] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 10 : 6[3] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 10 : 7[4] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Ring 11 : 0[5] -> 7[4] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [1] NCCL INFO Ring 11 : 1[6] -> 0[5] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [2] NCCL INFO Ring 11 : 2[0] -> 1[6] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [3] NCCL INFO Ring 11 : 3[7] -> 4[1] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [4] NCCL INFO Ring 11 : 4[1] -> 2[0] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [5] NCCL INFO Ring 11 : 5[2] -> 3[7] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [6] NCCL INFO Ring 11 : 6[3] -> 5[2] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [7] NCCL INFO Ring 11 : 7[4] -> 6[3] via P2P/direct pointer\\n4a9d6ecdefb4441890bb3c36394c16fc000001:208:208 [0] NCCL INFO Launch mode Group/CGMD\\n[08-17 17:55:19] epoch 0, batch 0, batch_loss=10.7519\\n[08-17 17:56:38] epoch 0, batch 100, batch_loss=4.6187\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.11.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = Experiment(ws, name=\"HydraNet\")\n",
    "run = experiment.submit(train_est)\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
