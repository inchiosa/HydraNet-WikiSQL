{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train HydraNet for WikiSQL benchmark\n",
    "\n",
    "## Prerequisites:\n",
    "- Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning (AML)\n",
    "- Install the Python SDK:  make sure to install notebook, and contrib\n",
    "    ```\n",
    "    conda create -n azureml -y Python=3.6\n",
    "    source activate azureml\n",
    "    pip install --upgrade azureml-sdk[notebooks,contrib]\n",
    "    conda install ipywidgets\n",
    "    jupyter nbextension install --py --user azureml.widgets\n",
    "    jupyter nbextension enable azureml.widgets --user --py\n",
    "    ```\n",
    " \n",
    "You will need to restart jupyter after this\n",
    "Detailed instructions are here: https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import AzureML SDK and initialize workspace\n",
    "\n",
    "To create or access an Azure ML Workspace, you will need to import the AML library and the following information:\n",
    "- A name for your workspace\n",
    "- Your subscription id\n",
    "- The resource group name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Run, RunConfiguration, ComputeTarget\n",
    "# Import AzureML Libraries\n",
    "import azureml.core\n",
    "from azureml.core import Datastore, Dataset,Experiment, Workspace, RunConfiguration, ContainerRegistry, Environment\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.data.datapath import DataPath, DataPathComputeBinding\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "from azureml.widgets import RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azureml.core.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.json', 'r') as config_file:\n",
    "    credentials = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve your workspace\n",
    "ws = Workspace.get(name=\"xiaoyzhu-turingrg\",\n",
    "                 subscription_id='a6c2a7cc-d67e-4a1a-b765-983f08c0423a',\n",
    "                  resource_group='xiaoyzhu-turingrg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Data Stores\n",
    "AML Workspace comes with a default data store. The training, validation and testing data is hosted <add description>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n"
     ]
    }
   ],
   "source": [
    "# Create the compute cluster\n",
    "gpu_cluster_name = \"nd40-ssh-2\" \n",
    "\n",
    "# Verify that the cluster doesn't exist already\n",
    "try:\n",
    "    gpu_compute_target = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_ND40rs_v2', min_nodes=0, max_nodes=1)\n",
    "    \n",
    "    # create the cluster\n",
    "    gpu_compute_target = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "    gpu_compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastore name: workspaceblobstore\n",
      "Container name: azureml-blobstore-1df38ad3-d561-413a-b8c5-603f11808774\n",
      "Datastore type: AzureBlob\n",
      "Workspace name: xiaoyzhu-turingrg\n"
     ]
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Print the workspace attributes\n",
    "print('Datastore name: ' + default_ds.name, \n",
    "      'Container name: ' + default_ds.container_name, \n",
    "      'Datastore type: ' + default_ds.datastore_type, \n",
    "      'Workspace name: ' + default_ds.workspace.name, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom environment based on Docker image \n",
    "\n",
    "We use a docker image built from the [Dockerfile](../dockerfile). Azure ML allows user to use a python environment in a custom docker image to run python scripts. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myenv = Environment(name=\"myenv\")\n",
    "myenv.docker.enabled = True\n",
    "myenv.docker.base_image = \"hydranet:v1\"\n",
    "myenv.docker.base_image_registry.address = \"marinchwus2a448b3c27.azurecr.io\"\n",
    "myenv.docker.base_image_registry.username = \"marinchwus2a448b3c27\"\n",
    "myenv.docker.base_image_registry.password = credentials[\"registry_password\"]\n",
    "myenv.python.user_managed_dependencies = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run fine-tuning PyTorch script\n",
    "Let us create a new PyTorch estimator to run the fine-tuning script `run_classifier.py`. \n",
    " \n",
    "AzureML provides mpi backend to launch python scripts in a process group. The helper module `azureml_adapter.py` sets up environment variables for pytorch so user can use `torch.distributed.init_process_group(backend=\"nccl\")` to initialize pytorch distributed process group with NCCL backend. \n",
    " \n",
    " \n",
    "PyTorch estimator parameters:\n",
    "- source_directory: the dictory of all source code to be executed in the remote compute target\n",
    "- compute_target: the compute target (created in the preparation step)\n",
    "- entry_script: the stript to be launched\n",
    "- node_count: how many nodes for the cluster to be created within the compute target to run this job\n",
    "- distributed_training: we use mpi to launch multiproces jobs in each node, allows pytorch to initialize process group using NCCL backend. Note that mpi configuration also sets number of processes for each node. This should be the same as the number of GPUs on each node. \n",
    "- environment_definition: use the custom environment. If omitted, Azure ML provides standard docker images for different pytorch versions.\n",
    " \n",
    "We explain a few script arguments, the rest are self-explainable\n",
    "- model_name_or_path: The location of the pretrained TuringV3 model\n",
    "- task_name: The GLUE task name. We use sst-2 here.\n",
    "- data_dir: The input of the training data from GLUE \n",
    "- output_dir: The output path of the fine-tuned model\n",
    "- per_gpu_train_batch_size: The batch size for each gpu in forward and backward steps\n",
    "- num_training_epochs: number of epochs to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If environment_definition or conda_dependencies_file_path is specified, Azure ML will not install any framework related packages on behalf of the user.\n"
     ]
    }
   ],
   "source": [
    "# workdir = \"/turing/workdir\"\n",
    "\n",
    "# mpi = MpiConfiguration()\n",
    "# mpi.process_count_per_node = 8 \n",
    "\n",
    "source_directory = '..'\n",
    "# model_checkpoint_path = \"NLRv3-Base-Uncased/tnlrv3-base.pt\"\n",
    "# dataset_path = 'glue/SST-2/'\n",
    "dataset_path = 'marinch/hydranet/'\n",
    "# output_path = 'outputs-marinch/hydranet-outputs/'\n",
    "\n",
    "train_est = PyTorch(source_directory=source_directory,\n",
    "                    compute_target=gpu_compute_target,\n",
    "                    script_params = {\n",
    "#                         '--model_name_or_path': ds.path(model_checkpoint_path).as_mount(),\n",
    "#                         '--task_name': 'sst-2',\n",
    "#                         '--tokenizer_name': './tnlrv3/tokenizer/tnlrv3-base-uncased-vocab.txt',\n",
    "#                         '--config_name': './tnlrv3/config/tnlrv3-base-uncased-config.json',\n",
    "#                         '--do_train': '',\n",
    "#                         '--do_lower_case':'', \n",
    "#                         '--evaluate_during_training':'',\n",
    "#                         '--data_dir':default_ds.path(dataset_path).as_mount(),\n",
    "#                         '--output_dir': default_ds.path(output_path).as_mount(),\n",
    "                        '--gpu': '0,1,2,3,4,5,6,7',\n",
    "#                         '--max_seq_length': 128, \n",
    "#                         '--per_gpu_train_batch_size': 32, \n",
    "#                         '--learning_rate': 7e-6,\n",
    "#                         '--num_train_epochs':2.0, # 25.0,\n",
    "#                         '--weight_decay':0.01, \n",
    "#                         '--warmup_ratio':0.2,\n",
    "#                         '--fp16':'',\n",
    "#                         '--fp16_opt_level': 'O2',\n",
    "#                         '--overwrite_output_dir':'',\n",
    "#                         '--do_eval':''\n",
    "                    },\n",
    "                    entry_script='notebooks/prep_and_train.py',\n",
    "#                     node_count=1,\n",
    "#                     distributed_training = mpi,\n",
    "                    environment_definition = myenv,\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--gpu': '0,1,2,3,4,5,6,7'\n",
    "}\n",
    "\n",
    "train_est = PyTorch(source_directory=source_directory, \n",
    "                    script_params=script_params,\n",
    "                    compute_target=gpu_compute_target,\n",
    "                    entry_script='notebooks/prep_and_train.py',\n",
    "                    use_gpu=True,\n",
    "                    framework_version='1.4',\n",
    "#                     pip_packages=['transformers==2.3.0', 'tqdm', 'records', 'babel', 'tabulate'],\n",
    "                    pip_requirements_file='requirements.txt',\n",
    "                    conda_packages=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training. On a Standard_ND40rs_v2 VM with 8 V100 GPUs, it takes about 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da91fb05bfb4a85bcf26417e27d6c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Queued\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/HydraNet/runs/HydraNet_1597704528_0c440c79?wsid=/subscriptions/a6c2a7cc-d67e-4a1a-b765-983f08c0423a/resourcegroups/xiaoyzhu-turingrg/workspaces/xiaoyzhu-turingrg\", \"run_id\": \"HydraNet_1597704528_0c440c79\", \"run_properties\": {\"run_id\": \"HydraNet_1597704528_0c440c79\", \"created_utc\": \"2020-08-17T22:49:02.408353Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"524c610e-1526-4807-9465-ff39d371d7e8\", \"azureml.git.repository_uri\": \"https://github.com/inchiosa/HydraNet-WikiSQL\", \"mlflow.source.git.repoURL\": \"https://github.com/inchiosa/HydraNet-WikiSQL\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"b1d84d0ad84fb0d8571b080495623e0d580fab9f\", \"mlflow.source.git.commit\": \"b1d84d0ad84fb0d8571b080495623e0d580fab9f\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"resizing\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":1,\\\"CurrentNodeCount\\\":1}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Queued\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:05:10\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.11.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment = Experiment(ws, name=\"HydraNet\")\n",
    "run = experiment.submit(train_est)\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
